{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled4.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6nuUuUBSZHU9"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import pandas as pd\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets,layers,models\n",
        "import matplotlib.pyplot as plt\n",
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1AGGEhaHZFbT",
        "outputId": "37974477-587a-492a-89c4-54851ac2ae41"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9hvBIXi5Yls"
      },
      "source": [
        "Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bX_O0yP7muNx"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/dataset/Action_Recognition/')"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3DJxx70OtttV",
        "outputId": "523dbf95-335e-4251-cfa6-1575aef1496e"
      },
      "source": [
        "ls"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[0m\u001b[01;34mdribling\u001b[0m/  \u001b[01;34mheadshot\u001b[0m/  \u001b[01;34mkicking\u001b[0m/  \u001b[01;34mrunning\u001b[0m/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQGKo5mOt0UA"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/dataset/Action_Recognition/dribling/')"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZF-tbmYenOQe"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "onlyfiles = [f for f in listdir() if isfile(join('',f))]\n",
        "Dribling = onlyfiles[1:]"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rnf_2ixBuCzV"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/dataset/Action_Recognition/headshot/')"
      ],
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0biq03uEuJ3h"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "onlyfiles = [f for f in listdir() if isfile(join('',f))]\n",
        "Headshot = onlyfiles[1:]"
      ],
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nYdH38cMuQO_"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/dataset/Action_Recognition/kick/')"
      ],
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3FMPWa1uVuh"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "onlyfiles = [f for f in listdir() if isfile(join('',f))]\n",
        "Kick = onlyfiles[1:]"
      ],
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTalqqjIubD4"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/dataset/Action_Recognition/running/')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctDoqyocue2v"
      },
      "source": [
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "onlyfiles = [f for f in listdir() if isfile(join('',f))]\n",
        "Running = onlyfiles[1:]"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fz1yY2MSujRl"
      },
      "source": [
        "DriblingTrain = Dribling[:int(len(Dribling)*0.7)]\n",
        "HeadshotTrain = Headshot[1:int(len(Headshot)*0.7)]\n",
        "KickTrain = Kick[1:int(len(Kick)*0.7)]\n",
        "RunningTrain=Running[1:int(len(Running)*0.7)]"
      ],
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVVZfvS7vYJy"
      },
      "source": [
        "trainNames = []\n",
        "for each in DriblingTrain:\n",
        "    trainNames.append(each)\n",
        "for each in HeadshotTrain:\n",
        "    trainNames.append(each)\n",
        "for each in KickTrain:\n",
        "    trainNames.append(each)\n",
        "for each in RunningTrain:\n",
        "    trainNames.append(each)  "
      ],
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R73GkRnIvqaX",
        "outputId": "ca20f86d-ca5a-47fb-f7cb-e2fb4344f3b7"
      },
      "source": [
        "\n",
        "len(trainNames)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "102"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8VkkO6Evvpy"
      },
      "source": [
        "DriblingTest = Dribling[int(len(Dribling)*0.7):]\n",
        "HeadshotTest = Headshot[int(len(Headshot)*0.7):]\n",
        "KickTest = Kick[int(len(Kick)*0.7):]\n",
        "RunningTest = Running[int(len(Running)*0.7):]\n"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KuYGhxEOwRXJ"
      },
      "source": [
        "testNames = []\n",
        "for each in DriblingTest :\n",
        "    testNames.append(each)\n",
        "for each in HeadshotTest:\n",
        "    testNames.append(each)\n",
        "for each in KickTest:\n",
        "    testNames.append(each)\n",
        "for each in RunningTest:\n",
        "    testNames.append(each)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mgvC1VMswhLx",
        "outputId": "be74b66d-eefa-4efe-84e2-0369d7f72595"
      },
      "source": [
        "len(testNames)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "Fl1j_9OVwn8M",
        "outputId": "4fd3f0cb-9c60-4477-e60a-1757cb4f559b"
      },
      "source": [
        "train = pd.DataFrame()\n",
        "train['video_Names']=trainNames\n",
        "train_video_tag = []\n",
        "for i in range(train.shape[0]):\n",
        "    train_video_tag.append(train['video_Names'][i].split('_')[1])\n",
        "train['tag'] = train_video_tag   \n",
        "train"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>video_Names</th>\n",
              "      <th>tag</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>v_dribling_g1_c3.mp4</td>\n",
              "      <td>dribling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>v_dribling_g1_c2.mp4</td>\n",
              "      <td>dribling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>v_dribling_g1_c1.mp4</td>\n",
              "      <td>dribling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>v_dribling_g2_c1.mp4</td>\n",
              "      <td>dribling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>v_dribling_g2_c2.mp4</td>\n",
              "      <td>dribling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>v_running_g6_c1.mp4</td>\n",
              "      <td>running</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>v_running_g7_c1.mp4</td>\n",
              "      <td>running</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>v_running_g8_c1.mp4</td>\n",
              "      <td>running</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>v_running_g9_c1.mp4</td>\n",
              "      <td>running</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>v_running_g10_c1.mp4</td>\n",
              "      <td>running</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>102 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "              video_Names       tag\n",
              "0    v_dribling_g1_c3.mp4  dribling\n",
              "1    v_dribling_g1_c2.mp4  dribling\n",
              "2    v_dribling_g1_c1.mp4  dribling\n",
              "3    v_dribling_g2_c1.mp4  dribling\n",
              "4    v_dribling_g2_c2.mp4  dribling\n",
              "..                    ...       ...\n",
              "97    v_running_g6_c1.mp4   running\n",
              "98    v_running_g7_c1.mp4   running\n",
              "99    v_running_g8_c1.mp4   running\n",
              "100   v_running_g9_c1.mp4   running\n",
              "101  v_running_g10_c1.mp4   running\n",
              "\n",
              "[102 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26xaCYQAwxVa"
      },
      "source": [
        "test = pd.DataFrame()\n",
        "test['video_Names']=testNames\n",
        "test_video_tag = []\n",
        "for i in range(test.shape[0]):\n",
        "    test_video_tag.append(test['video_Names'][i].split('_')[1])\n",
        "test['tag'] = test_video_tag    \n",
        "test"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mG_uJYuuxKp7"
      },
      "source": [
        "os.chdir('/content/drive/MyDrive/dataset/')"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FTQ2YRpHxr6j",
        "outputId": "13869095-d7c7-4f11-ecc8-673a6ddcb185"
      },
      "source": [
        "#frames extraction\n",
        "count=0\n",
        "for i in tqdm(range(train.shape[0])):\n",
        "\n",
        "    videoFile = train['video_Names'][i].split(\" \")[0].split(\"_\")[1]+\"/\"+train['video_Names'][i]\n",
        "    cap = cv2.VideoCapture('Action_Recognition/'+videoFile)\n",
        "    frameRate = cap.get(5)\n",
        "    while(cap.isOpened()):\n",
        "        frameId = cap.get(1) #current frame number\n",
        "        ret, frame = cap.read()\n",
        "        if (ret != True):\n",
        "            break\n",
        "        if (frameId % math.floor(frameRate) == 0):\n",
        "        \n",
        "            # storing the frames in a new folder named train_1\n",
        "        \n",
        "            filename ='train/' + train[\"video_Names\"][i].split(\"_\")[1]+\"_\"+train[\"video_Names\"][i].split(\"_\")[2]+ train[\"video_Names\"][i].split(\"_\")[3].split(\".\")[0] +\"_frame%d.jpg\" %count\n",
        "            count = count+1\n",
        "            cv2.imwrite(filename, frame)\n",
        "\n",
        "    cap.release()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 102/102 [00:11<00:00,  8.78it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGznfGGSq_8X"
      },
      "source": [
        "images = glob(\"train/*.jpg\")"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VyRNa1ZlrKYz",
        "outputId": "229f8095-d651-4d33-eb2c-6dabc4b24aa7"
      },
      "source": [
        "train_image = []\n",
        "train_class =[]\n",
        "for i in tqdm(range(len(images))):\n",
        "    train_image.append(images[i].split('/')[1])\n",
        "    train_class.append(images[i].split('/')[1].split(\"_\")[0])"
      ],
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 110/110 [00:00<00:00, 69809.87it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "bpxOjrFarqZB",
        "outputId": "f986897e-1344-42e3-8bc8-2de0f4119816"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/dataset'"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JL6y8_gVriHY"
      },
      "source": [
        "train_data = pd.DataFrame()\n",
        "train_data['image'] = train_image\n",
        "train_data['class'] = train_class\n",
        "\n",
        "# converting the dataframe into csv file \n",
        "train_data.to_csv('/content/drive/MyDrive/dataset/train_new.csv',header=True, index=False)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCzYhNoiryot",
        "outputId": "e5d61d28-ecac-4322-ab46-7845be29efef"
      },
      "source": [
        "count=0\n",
        "for i in tqdm(range(test.shape[0])):\n",
        "    \n",
        "    videoFile = test['video_Names'][i].split(\" \")[0].split(\"_\")[1]+\"/\"+test['video_Names'][i]\n",
        "    cap = cv2.VideoCapture('Action_Recognition/'+videoFile)\n",
        "    frameRate = cap.get(5)\n",
        "    while(cap.isOpened()):\n",
        "        frameId = cap.get(1)\n",
        "        ret, frame = cap.read()\n",
        "        if (ret != True):\n",
        "            break\n",
        "        if (frameId % math.floor(frameRate) == 0):\n",
        "            filename = 'test/' + test[\"video_Names\"][i].split(\"_\")[1]+\"_\"+test['video_Names'][i].split(\"_\")[2]+test['video_Names'][i].split(\"_\")[3].split(\".\")[0]+\"_frame%d.jpg\" %count\n",
        "            count = count+1\n",
        "            cv2.imwrite(filename, frame)\n",
        "            \n",
        "    cap.release()"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 47/47 [00:01<00:00, 44.42it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5xDzRbVsAdo"
      },
      "source": [
        "images = glob(\"test/*.jpg\")\n",
        "images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAgAUfystWwq",
        "outputId": "96ce8430-b5e8-4981-ef6d-e29edc487096"
      },
      "source": [
        "test_image = []\n",
        "test_class =[]\n",
        "for i in tqdm(range(len(images))):\n",
        "    test_image.append(images[i].split('/')[1])\n",
        "    test_class.append(images[i].split('/')[1].split(\"_\")[0])"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 53/53 [00:00<00:00, 212725.47it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lwNqnVPNtmoD"
      },
      "source": [
        "test_data = pd.DataFrame()\n",
        "test_data['image'] = test_image\n",
        "test_data['class'] = test_class\n",
        "\n",
        "# converting the dataframe into csv file \n",
        "test_data.to_csv('/content/drive/MyDrive/dataset/test_new.csv',header=True, index=False)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eniaXpRt1mT"
      },
      "source": [
        "import IPython.display as display\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OxAWpMwCt_s1",
        "outputId": "0174b994-be44-4ff1-f784-cc26b9abba8c"
      },
      "source": [
        "cd .."
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bRjtKr55fz-"
      },
      "source": [
        "CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2eJohFf0uB58"
      },
      "source": [
        "image_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F_vOoGBYuGFT"
      },
      "source": [
        "CLASS_NAMES = [\"dribling\",\"headshot\",\"kick\",\"running\"]"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnwZ7JAvu-BB",
        "outputId": "ae675103-1bb3-49ce-c58d-ce3dfd8e6ebc"
      },
      "source": [
        "cd dataset"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Errno 2] No such file or directory: 'dataset'\n",
            "/content/drive/MyDrive/dataset\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wUlcGc59uarI",
        "outputId": "11397c4d-12f3-40e8-c599-a11dcdde313d"
      },
      "source": [
        "#frames preprocessing\n",
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    shear_range = 0.2,\n",
        "    zoom_range = 0.2,\n",
        "    horizontal_flip = True)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'train/',\n",
        "    target_size= (256, 256),\n",
        "    color_mode = 'rgb')\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    'test/',\n",
        "    target_size= (256, 256),\n",
        "    batch_size = 5,\n",
        "    color_mode = 'rgb')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 105 images belonging to 3 classes.\n",
            "Found 50 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RyACwY4Q3bv9",
        "outputId": "8916c827-850b-4188-8b35-af21c1c28f2a"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(32, (3,3), input_shape = (256,256,3), activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(layers.Dropout(0.05))\n",
        "model.add(layers.Conv2D(32, (3,3), activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(layers.Dropout(0.07))\n",
        "model.add(layers.Conv2D(64, (3,3), activation = 'relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size = (2,2)))\n",
        "model.add(layers.Dropout(0.15))\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(200, activation = 'relu'))\n",
        "model.add(layers.Dropout(0.4))\n",
        "model.add(layers.Dense(3, activation = 'softmax'))\n",
        "model.compile(loss = tf.keras.losses.CategoricalCrossentropy(),\n",
        "             optimizer = 'adam',\n",
        "             metrics = ['accuracy'])\n",
        "\n",
        "history=model.fit(train_generator,epochs =10,validation_data=validation_generator)\n",
        "model.save(\"/content/drive/My Drive/dataset/modelCNN.h5\")"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "4/4 [==============================] - 9s 2s/step - loss: 2.7345 - accuracy: 0.3714 - val_loss: 1.0275 - val_accuracy: 0.2400\n",
            "Epoch 2/10\n",
            "4/4 [==============================] - 8s 2s/step - loss: 0.8975 - accuracy: 0.4952 - val_loss: 0.8805 - val_accuracy: 0.6400\n",
            "Epoch 3/10\n",
            "4/4 [==============================] - 8s 2s/step - loss: 0.6608 - accuracy: 0.7048 - val_loss: 0.7481 - val_accuracy: 0.6400\n",
            "Epoch 4/10\n",
            "4/4 [==============================] - 8s 2s/step - loss: 0.5895 - accuracy: 0.7524 - val_loss: 0.7043 - val_accuracy: 0.6600\n",
            "Epoch 5/10\n",
            "4/4 [==============================] - 8s 2s/step - loss: 0.4966 - accuracy: 0.8286 - val_loss: 0.6975 - val_accuracy: 0.6600\n",
            "Epoch 6/10\n",
            "4/4 [==============================] - 8s 2s/step - loss: 0.4174 - accuracy: 0.8190 - val_loss: 0.7442 - val_accuracy: 0.6200\n",
            "Epoch 7/10\n",
            "4/4 [==============================] - 8s 2s/step - loss: 0.3263 - accuracy: 0.8762 - val_loss: 0.6970 - val_accuracy: 0.7000\n",
            "Epoch 8/10\n",
            "4/4 [==============================] - 8s 2s/step - loss: 0.4003 - accuracy: 0.8095 - val_loss: 0.6655 - val_accuracy: 0.7000\n",
            "Epoch 9/10\n",
            "4/4 [==============================] - 8s 2s/step - loss: 0.3497 - accuracy: 0.8381 - val_loss: 0.7453 - val_accuracy: 0.6200\n",
            "Epoch 10/10\n",
            "4/4 [==============================] - 8s 2s/step - loss: 0.3538 - accuracy: 0.8476 - val_loss: 1.0204 - val_accuracy: 0.6800\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rNnvN9T34HzD",
        "outputId": "8c0bb888-822a-4564-a1f3-fbca37cfcda1"
      },
      "source": [
        "model.evaluate(validation_generator)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10/10 [==============================] - 1s 88ms/step - loss: 1.0204 - accuracy: 0.6800\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.0203996896743774, 0.6800000071525574]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ICRJ9Eh44NcI",
        "outputId": "0de49a5d-9185-4d84-b6af-bbbac4643ed8"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_3 (Conv2D)            (None, 254, 254, 32)      896       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 127, 127, 32)      0         \n",
            "_________________________________________________________________\n",
            "dropout_4 (Dropout)          (None, 127, 127, 32)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 125, 125, 32)      9248      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 62, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_5 (Dropout)          (None, 62, 62, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 60, 60, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_5 (MaxPooling2 (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "dropout_6 (Dropout)          (None, 30, 30, 64)        0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 57600)             0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 200)               11520200  \n",
            "_________________________________________________________________\n",
            "dropout_7 (Dropout)          (None, 200)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 3)                 603       \n",
            "=================================================================\n",
            "Total params: 11,549,443\n",
            "Trainable params: 11,549,443\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FGpJ6H6n4Ttr",
        "outputId": "faa34d9c-86e2-42b6-967c-fad312f6447c"
      },
      "source": [
        "from keras.callbacks import History \n",
        "\n",
        "print(history.history.keys())"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        },
        "id": "ChkYk3KC4X04",
        "outputId": "8fd6401e-6f20-4888-b23a-abcdea1ca3ea"
      },
      "source": [
        "loss_train = history.history['loss']\n",
        "loss_val = history.history['val_loss']\n",
        "epochs = range(1,11)\n",
        "plt.plot(epochs, loss_train, 'g', label='Training loss')\n",
        "plt.plot(epochs, loss_val, 'b', label='validation loss')\n",
        "accuracy_train = history.history['accuracy']\n",
        "accuracy_val = history.history['val_accuracy']\n",
        "plt.plot(epochs, accuracy_train, 'r', label='Training accuracy')\n",
        "plt.plot(epochs, accuracy_val, 'y', label='validation accuracy')\n",
        "plt.title('Training and Validation loss and accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss/Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nnXHhj_B4lSL"
      },
      "source": [
        ""
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "mlp1__Hi4qGk",
        "outputId": "96c0ce35-f7a3-4bab-ceb2-9ab7a9f77b9f"
      },
      "source": [
        "pwd\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/dataset'"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BH7aQDnM4vhI"
      },
      "source": [
        "from keras.models import load_model\n",
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from keras.preprocessing import image\n",
        "model=load_model('/content/drive/My Drive/dataset/modelCNN.h5')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KgcwwryrVSe6",
        "outputId": "2e442e02-bf19-4962-b227-412c704893a6"
      },
      "source": [
        "pwd"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/dataset'"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKsfcnVEUe5U",
        "outputId": "7e791fbc-6ed7-46bc-abf0-087d0e9a5441"
      },
      "source": [
        "#prediction\n",
        "test_image=image.load_img('test/headshot/headshot_g19c21_frame34.jpg',target_size=(256,256))\n",
        "\n",
        "test_image=image.img_to_array(test_image)\n",
        "test_image=np.expand_dims(test_image,axis=0)\n",
        "label=model.predict(test_image)\n",
        "print(label)\n",
        "\n",
        "if label[0][2]==1:\n",
        "    print('kick')\n",
        "elif label[0][0]==1:\n",
        "    print('dribling')\n",
        "elif label[0][1]==1:\n",
        "    print('headshot')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 0.]]\n",
            "headshot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXPBohz9WBdz"
      },
      "source": [
        "LSTM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r98hIAFa6NS3"
      },
      "source": [
        "Part 1: Spacial Featuring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ot686N4rdrmi"
      },
      "source": [
        "modelfeatured=models.Model(\n",
        "    inputs=model.input,\n",
        "    outputs=model.get_layer('flatten_1').output\n",
        ")"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Np9RYQHDeFm8"
      },
      "source": [
        "modelfeatured1 = models.Model(\n",
        "    inputs=model.input,\n",
        "    outputs=model.get_layer('dense_2').output\n",
        ")"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M9YOZwqseLd8",
        "outputId": "3c8afcbb-c76e-47a0-bdb7-5007f0262ca0"
      },
      "source": [
        "base_model = tf.keras.applications.inception_v3.InceptionV3(\n",
        "    weights='imagenet',\n",
        "    include_top=True\n",
        ")\n",
        "# We'll extract features at the final pool layer.\n",
        "modelfeatured3 = models.Model(\n",
        "    inputs=base_model.input,\n",
        "    outputs=base_model.get_layer('avg_pool').output\n",
        ")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
            "96116736/96112376 [==============================] - 1s 0us/step\n",
            "96124928/96112376 [==============================] - 1s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pdgiif8TeXHY",
        "outputId": "14f14b69-444e-4016-9c8e-8a2fbfe30155"
      },
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "  rescale = 1./255,\n",
        "  validation_split=0.2,\n",
        "  shear_range = 0.2, # random application of shearing\n",
        "  zoom_range = 0.2,\n",
        "  horizontal_flip = True) # randomly flipping half of the images horizontally\n",
        "train_datagen\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "  'train/',\n",
        "  target_size = (256, 256),\n",
        "  shuffle = True,\n",
        "  color_mode = 'rgb')\n",
        "  \n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "  'test/',\n",
        "  target_size = (256, 256),\n",
        "  batch_size = 15,\n",
        "  shuffle=True,\n",
        "  color_mode = 'rgb')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 105 images belonging to 3 classes.\n",
            "Found 50 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "88kDIQQoejbM"
      },
      "source": [
        "modelfeatured = modelfeatured1\n",
        "#modelfeatured = modelfeatured2\n",
        "#modelfeatured = modelfeatured\n",
        "\n",
        "train_featured = modelfeatured.predict(train_generator)\n",
        "test_featured = modelfeatured.predict(validation_generator)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eaNfMp2memmM"
      },
      "source": [
        "np.savetxt('/content/drive/MyDrive/dataset/ftrainf.csv',train_featured, delimiter=',')\n",
        "np.savetxt('/content/drive/MyDrive/dataset/ftestf.csv',test_featured, delimiter=',')"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e-V7q6d6aze"
      },
      "source": [
        "Part 2: Temporal Featuring"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FSlR-LkVemwr",
        "outputId": "56210542-7433-4705-a40b-25a88fc0d4ca"
      },
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "      shear_range = 0.2, # random application of shearing\n",
        "      zoom_range = 0.2,\n",
        "      validation_split=0.2,\n",
        "      horizontal_flip = True) # randomly flipping half of the images horizontally\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "      'train/',\n",
        "      target_size = (256, 256),\n",
        "      shuffle = True,\n",
        "      color_mode = \"rgb\")"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 105 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4V1uiQnBe4xR"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(256, kernel_size=(1, 1),input_shape=(256,256, 3)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(layers.MaxPooling2D((3, 3)))\n",
        "\n",
        "model.add(layers.Conv2D(128, (3, 3)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (3, 3)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(layers.Conv2D(64, (1, 1)))\n",
        "model.add(tf.keras.layers.BatchNormalization())\n",
        "model.add(tf.keras.layers.Activation('relu'))\n",
        "model.add(layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "\n",
        "model.add(layers.Flatten())\n",
        "\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.3))\n",
        "\n",
        "model.add(layers.Dense(64, activation='relu'))\n",
        "model.add(layers.Dropout(0.3))       \n",
        "model.add(layers.Dense(3, activation='softmax'))"
      ],
      "execution_count": 100,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KBGZNjTfN1s",
        "outputId": "bce092c1-3a04-4280-822c-01eeab748542"
      },
      "source": [
        "model.compile(optimizer=\"adam\",loss=tf.keras.losses.CategoricalCrossentropy(),metrics=['accuracy'])\n",
        "#model.load_weights('modelCNN.h5')\n",
        "callback = tf.keras.callbacks.EarlyStopping(patience=3)\n",
        "model.fit(train_generator,epochs=9,batch_size=6)\n",
        "model.save_weights(\"modelFF.h5\")"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/9\n",
            "4/4 [==============================] - 46s 11s/step - loss: 1.2450 - accuracy: 0.4476\n",
            "Epoch 2/9\n",
            "4/4 [==============================] - 43s 10s/step - loss: 0.8948 - accuracy: 0.6000\n",
            "Epoch 3/9\n",
            "4/4 [==============================] - 42s 10s/step - loss: 0.7515 - accuracy: 0.6667\n",
            "Epoch 4/9\n",
            "4/4 [==============================] - 42s 10s/step - loss: 0.6900 - accuracy: 0.6667\n",
            "Epoch 5/9\n",
            "4/4 [==============================] - 42s 10s/step - loss: 0.6823 - accuracy: 0.7333\n",
            "Epoch 6/9\n",
            "4/4 [==============================] - 42s 13s/step - loss: 0.5858 - accuracy: 0.7333\n",
            "Epoch 7/9\n",
            "4/4 [==============================] - 42s 13s/step - loss: 0.4243 - accuracy: 0.8190\n",
            "Epoch 8/9\n",
            "4/4 [==============================] - 42s 10s/step - loss: 0.2867 - accuracy: 0.8952\n",
            "Epoch 9/9\n",
            "4/4 [==============================] - 42s 10s/step - loss: 0.2956 - accuracy: 0.9238\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Exg0CA3kkel6",
        "outputId": "7d36a6c9-fb95-46d7-b175-5735989326fc"
      },
      "source": [
        "model.evaluate(train_generator)"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4/4 [==============================] - 10s 2s/step - loss: 0.9535 - accuracy: 0.6476\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.9535433053970337, 0.6476190686225891]"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1hNIycxkgij",
        "outputId": "71c4e763-9d4d-4423-eb7a-64eefc17e7c0"
      },
      "source": [
        "train_datagen =  tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        'train/',\n",
        "        target_size=(256, 256),\n",
        "        color_mode=\"rgb\",\n",
        "        shuffle = False,\n",
        "        class_mode='categorical',\n",
        "        batch_size=1)\n",
        "\n",
        "filenames = train_generator.filenames\n",
        "nb_samples = len(filenames)\n",
        "\n",
        "predict = model.predict_generator(train_generator)\n",
        "frame = pd.DataFrame(predict, columns=[1,2,3])\n",
        "feature_train_1 = pd.DataFrame(frame.idxmax(axis=1),columns=[\"class\"])"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 105 images belonging to 3 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xI5L6eOblMYe",
        "outputId": "ee27ad08-afbd-47d4-a12b-847caf51461e"
      },
      "source": [
        "test_datagen1 =  tf.keras.preprocessing.image.ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "test_generator1 = test_datagen1.flow_from_directory(\n",
        "        'test/',\n",
        "        target_size=(256, 256),\n",
        "        color_mode=\"rgb\",\n",
        "        shuffle = False,\n",
        "        class_mode='categorical',\n",
        "        batch_size=1)\n",
        "\n",
        "filenames = test_generator1.filenames\n",
        "nb_samples = len(filenames)\n",
        "\n",
        "predict = model.predict_generator(test_generator1)\n",
        "frame = pd.DataFrame(predict, columns=[1,2,3])\n",
        "feature_test_1 = pd.DataFrame(frame.idxmax(axis=1),columns=[\"class\"])"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 50 images belonging to 3 classes.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:2035: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
            "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CqnkhtcQldSn",
        "outputId": "334b2666-41ea-4d9d-8dbb-a48972976294"
      },
      "source": [
        "mkdir features"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘features’: File exists\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7R1ain5DllHP"
      },
      "source": [
        "feature_test_1.to_csv('features/feature_test_1.csv', index=False)\n",
        "feature_train_1.to_csv('features/feature_train_1.csv', index=False)"
      ],
      "execution_count": 105,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TW3X-KZBl0a4"
      },
      "source": [
        "feature_test_1 = pd.read_csv('features/feature_test_1.csv')\n",
        "feature_train_1 = pd.read_csv('features/feature_train_1.csv')"
      ],
      "execution_count": 106,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HnhIJ4Im6vfm"
      },
      "source": [
        "Part 3: LSTM Modelling\n",
        "Here LSTM model is build on the sequenced dataframes from each video These dataframes have \n",
        "extracted  1.spacial features from the cnn model  2.temporal features from cnn or other models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kwBYHvYNm4vj"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.cluster import KMeans"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gvkw1LOJl2nC"
      },
      "source": [
        "df = np.genfromtxt('ftrainf.csv', delimiter=',')\n",
        "scaler=MinMaxScaler()\n",
        "\n",
        "scaled=scaler.fit_transform(df)\n",
        "df=pd.DataFrame(scaled)\n",
        "\n",
        "kmean4=KMeans(n_clusters=4)\n",
        "kmean4.fit(df)\n",
        "y_hat = kmean4.predict(df)\n",
        "feature_train_2 = y_hat.reshape(y_hat.shape[0],1)"
      ],
      "execution_count": 107,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fc2grHBfnMyn"
      },
      "source": [
        "np.savetxt('features/feature_test_2.csv',feature_test_1, delimiter=',')\n",
        "np.savetxt('features/feature_train_2.csv',feature_train_1, delimiter=',')\n",
        "feature_test_2 = np.genfromtxt('features/feature_test_2.csv', delimiter=',')\n",
        "feature_train_2 = np.genfromtxt('features/feature_train_2.csv', delimiter=',')\n",
        "feature_train_2 = feature_train_2.reshape(feature_train_2.shape[0],1)\n",
        "feature_test_2 = feature_test_2.reshape(feature_test_2.shape[0],1)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C_yFxa10ndR3"
      },
      "source": [
        "train_featured = np.genfromtxt('ftrainf.csv', delimiter=',')\n",
        "test_featured = np.genfromtxt('ftestf.csv', delimiter=',')\n",
        "n_steps = 5  ##We set frame rate as 30\n",
        "n_features = test_featured.shape[1]"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qbCxLsk-nkoT"
      },
      "source": [
        "test_featured = np.append(test_featured,feature_test_1,axis=1)\n",
        "train_featured = np.append(train_featured,feature_train_1,axis=1)\n",
        "test_featured = np.append(test_featured,feature_test_2,axis=1)\n",
        "train_featured = np.append(train_featured,feature_train_2,axis=1)"
      ],
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WnPwGA8Knn43",
        "outputId": "0cca4b90-8ab8-404c-b6cd-d0af2ec4c7f2"
      },
      "source": [
        "train_featured.shape"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(105, 202)"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz18mpzBnoE2"
      },
      "source": [
        "temp = train_featured[:n_steps]\n",
        "temp = temp.reshape(1,n_steps,temp.shape[1])\n",
        "for i in range(n_steps,train_featured.shape[0],n_steps):\n",
        "  temp = np.append(temp,train_featured[i:i+n_steps].reshape(1,n_steps,train_featured.shape[1]),axis = 0)\n",
        "trainX = temp\n",
        "temp = test_featured[:n_steps]\n",
        "temp = temp.reshape(1,temp.shape[0],temp.shape[1])\n",
        "for i in range(n_steps,test_featured.shape[0],n_steps):\n",
        "  temp = np.append(temp,test_featured[i:i+n_steps].reshape(1,n_steps,test_featured.shape[1]),axis = 0)\n",
        "testX = temp"
      ],
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SEajQU1mnoPY",
        "outputId": "c0726bff-ff5e-4714-db27-705ef253e8f1"
      },
      "source": [
        "trainX.shape"
      ],
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(21, 5, 202)"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vikCSbIBnoUV",
        "outputId": "58750a98-7fa2-46a0-9f51-8b735ff993ff"
      },
      "source": [
        "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "      rescale = 1./255,\n",
        "      #validation_split=0.2,\n",
        "      shear_range = 0.2, # random application of shearing\n",
        "      zoom_range = 0.2,\n",
        "      horizontal_flip = True) # randomly flipping half of the images horizontally\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    'train/',\n",
        "    target_size = (256, 256),\n",
        "    shuffle = False,\n",
        "    color_mode = \"rgb\")\n",
        "test_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)\n",
        "validation_generator = test_datagen.flow_from_directory(\n",
        "    'test/',\n",
        "    target_size = (256, 256),\n",
        "    batch_size = 15,\n",
        "    shuffle=False,\n",
        "    color_mode = 'rgb')"
      ],
      "execution_count": 114,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 105 images belonging to 3 classes.\n",
            "Found 50 images belonging to 3 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQB_kZSinoYZ"
      },
      "source": [
        "y_train = []\n",
        "for i in train_generator.filenames:\n",
        "  if(i.split(\"/\")[0]==\"dribling\"):\n",
        "    y_train.append(-100) \n",
        "  elif(i.split(\"/\")[0]==\"headshot\"):\n",
        "    y_train.append(0)\n",
        "  elif(i.split(\"/\")[0]==\"kick\"):\n",
        "    y_train.append(100) \n",
        "\n",
        "y_test = []\n",
        "for i in validation_generator.filenames:\n",
        "  if(i.split(\"/\")[0]==\"dribling\"):\n",
        "    y_test.append(-100) \n",
        "  elif(i.split(\"/\")[0]==\"headshot\"):\n",
        "    y_test.append(0)\n",
        "  elif(i.split(\"/\")[0]==\"kick\"):\n",
        "    y_test.append(100) \n",
        "\n",
        "trainY=[]\n",
        "for i in range(0,len(y_train),n_steps):\n",
        "  trainY.append(y_train[i])\n",
        "testY=[]\n",
        "for i in range(0,len(y_test),n_steps):\n",
        "  testY.append(y_test[i])\n",
        "\n",
        "\n",
        "trainY = np.array(trainY)\n",
        "testY = np.array(testY)\n",
        "\n",
        "trainY=[]\n",
        "for i in range(0,len(y_train),n_steps):\n",
        "  trainY.append(y_train[i])\n",
        "testY=[]\n",
        "for i in range(0,len(y_test),n_steps):\n",
        "  testY.append(y_test[i])\n",
        "\n",
        "TRAINy = pd.DataFrame(trainY)\n",
        "TRAINy.columns = ['label']\n",
        "TRAINy['1']=0\n",
        "TRAINy['2']=0\n",
        "TRAINy['3']=0\n",
        "for i in TRAINy.loc[TRAINy['label']==-100].index:\n",
        "  TRAINy.loc[i,\"1\"]=1\n",
        "for i in TRAINy.loc[TRAINy['label']==0].index:\n",
        "  TRAINy.loc[i,\"2\"]=1\n",
        "for i in TRAINy.loc[TRAINy['label']==100].index:\n",
        "  TRAINy.loc[i,\"3\"]=1\n",
        "final_trainY =np.array(TRAINy[['1','2','3']])\n",
        "\n",
        "TESTy = pd.DataFrame(testY)\n",
        "TESTy.columns = ['label']\n",
        "TESTy['1']=0\n",
        "TESTy['2']=0\n",
        "TESTy['3']=0\n",
        "for i in TESTy.loc[TESTy['label']==-100].index:\n",
        "  TESTy.loc[i,\"1\"]=1\n",
        "for i in TESTy.loc[TESTy['label']==0].index:\n",
        "  TESTy.loc[i,\"2\"]=1\n",
        "for i in TESTy.loc[TESTy['label']==100].index:\n",
        "  TESTy.loc[i,\"3\"]=1\n",
        "final_testY = np.array(TESTy[['1','2','3']])"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GVZTy3YWnodt",
        "outputId": "83e09aa2-5f84-44af-e6fe-fe39e6e4916a"
      },
      "source": [
        "testX.shape"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 5, 202)"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vg9mLBV8nog-"
      },
      "source": [
        "model2 = models.Sequential()\n",
        "model2.add(layers.LSTM(500, activation='relu', return_sequences=True, input_shape=(n_steps, n_features+2)))\n",
        "model2.add(tf.keras.layers.BatchNormalization())\n",
        "model2.add(layers.LSTM(500, activation='relu'))\n",
        "model2.add(layers.Dense(3,activation=\"softmax\"))"
      ],
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1p3rRGabnold",
        "outputId": "5e01e1b2-44f2-4382-e4ec-00ffe4ae81db"
      },
      "source": [
        "optimizer = tf.keras.optimizers.Adam(lr=1e-4, decay=1e-5)\n",
        "model2.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer='adam',\n",
        "                    metrics=['accuracy','top_k_categorical_accuracy'])\n",
        "#model2.load_weights(\"modelLstm.h5\")\n",
        "model2.fit(trainX,final_trainY,validation_data=(testX,final_testY),batch_size=8,epochs=20)\n",
        "model2.evaluate(testX,final_testY,batch_size = 8)\n",
        "model2.save(\"modelLstm.h5\")"
      ],
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/optimizer_v2/optimizer_v2.py:356: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
            "  \"The `lr` argument is deprecated, use `learning_rate` instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "3/3 [==============================] - 3s 250ms/step - loss: 0.0306 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 2.8519 - val_accuracy: 0.8000 - val_top_k_categorical_accuracy: 1.0000\n",
            "Epoch 2/20\n",
            "3/3 [==============================] - 0s 80ms/step - loss: 2.0689e-04 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.7332 - val_accuracy: 0.7000 - val_top_k_categorical_accuracy: 1.0000\n",
            "Epoch 3/20\n",
            "3/3 [==============================] - 0s 74ms/step - loss: 0.0097 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.1260 - val_accuracy: 0.7000 - val_top_k_categorical_accuracy: 1.0000\n",
            "Epoch 4/20\n",
            "3/3 [==============================] - 0s 84ms/step - loss: 2.1004e-07 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 3.0745 - val_accuracy: 0.6000 - val_top_k_categorical_accuracy: 1.0000\n",
            "Epoch 5/20\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 5.9540e-04 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.9158 - val_accuracy: 0.7000 - val_top_k_categorical_accuracy: 1.0000\n",
            "Epoch 6/20\n",
            "3/3 [==============================] - 0s 86ms/step - loss: 9.0481e-06 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.8556 - val_accuracy: 0.6000 - val_top_k_categorical_accuracy: 1.0000\n",
            "Epoch 7/20\n",
            "3/3 [==============================] - 0s 87ms/step - loss: 0.0146 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.8829 - val_accuracy: 0.6000 - val_top_k_categorical_accuracy: 1.0000\n",
            "Epoch 8/20\n",
            "3/3 [==============================] - 0s 78ms/step - loss: 1.2721e-05 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.9163 - val_accuracy: 0.8000 - val_top_k_categorical_accuracy: 1.0000\n",
            "Epoch 9/20\n",
            "3/3 [==============================] - 0s 78ms/step - loss: 0.3917 - accuracy: 0.9524 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.5346 - val_accuracy: 0.7000 - val_top_k_categorical_accuracy: 1.0000\n",
            "Epoch 10/20\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 0.0819 - accuracy: 0.9524 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.9043 - val_accuracy: 0.7000 - val_top_k_categorical_accuracy: 1.0000\n",
            "Epoch 11/20\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 2.1571e-07 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 5.6813 - val_accuracy: 0.6000 - val_top_k_categorical_accuracy: 1.0000\n",
            "Epoch 12/20\n",
            "3/3 [==============================] - 0s 79ms/step - loss: 5.6766e-08 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 10.4022 - val_accuracy: 0.5000 - val_top_k_categorical_accuracy: 1.0000\n",
            "Epoch 13/20\n",
            "3/3 [==============================] - 0s 82ms/step - loss: 1.3448 - accuracy: 0.9048 - top_k_categorical_accuracy: 1.0000 - val_loss: 11.1121 - val_accuracy: 0.5000 - val_top_k_categorical_accuracy: 1.0000\n",
            "Epoch 14/20\n",
            "3/3 [==============================] - 0s 81ms/step - loss: 1.0466 - accuracy: 0.9048 - top_k_categorical_accuracy: 1.0000 - val_loss: 4.8168 - val_accuracy: 0.5000 - val_top_k_categorical_accuracy: 1.0000\n",
            "Epoch 15/20\n",
            "3/3 [==============================] - 0s 85ms/step - loss: 3.1688e-05 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.7467 - val_accuracy: 0.6000 - val_top_k_categorical_accuracy: 1.0000\n",
            "Epoch 16/20\n",
            "3/3 [==============================] - 0s 74ms/step - loss: 0.0536 - accuracy: 0.9524 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.9723 - val_accuracy: 0.7000 - val_top_k_categorical_accuracy: 1.0000\n",
            "Epoch 17/20\n",
            "3/3 [==============================] - 0s 79ms/step - loss: 1.9568e-04 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 0.7738 - val_accuracy: 0.7000 - val_top_k_categorical_accuracy: 1.0000\n",
            "Epoch 18/20\n",
            "3/3 [==============================] - 0s 80ms/step - loss: 4.2114e-05 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.0193 - val_accuracy: 0.8000 - val_top_k_categorical_accuracy: 1.0000\n",
            "Epoch 19/20\n",
            "3/3 [==============================] - 0s 83ms/step - loss: 0.0107 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.2735 - val_accuracy: 0.8000 - val_top_k_categorical_accuracy: 1.0000\n",
            "Epoch 20/20\n",
            "3/3 [==============================] - 0s 80ms/step - loss: 4.2684e-05 - accuracy: 1.0000 - top_k_categorical_accuracy: 1.0000 - val_loss: 1.4148 - val_accuracy: 0.8000 - val_top_k_categorical_accuracy: 1.0000\n",
            "2/2 [==============================] - 0s 13ms/step - loss: 1.4148 - accuracy: 0.8000 - top_k_categorical_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9aGAPauErasY",
        "outputId": "5ea77219-d628-49b5-a010-2a41cb6378e0"
      },
      "source": [
        "model2.evaluate(testX,final_testY,batch_size = 8)"
      ],
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2/2 [==============================] - 0s 12ms/step - loss: 1.4148 - accuracy: 0.8000 - top_k_categorical_accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.414771556854248, 0.800000011920929, 1.0]"
            ]
          },
          "metadata": {},
          "execution_count": 156
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DkeIpGV7notZ",
        "outputId": "3d6ab71d-865c-4315-f0bb-43b442fa29a5"
      },
      "source": [
        "import cv2\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "\n",
        "#model1=load_model(\"modelCNN.h5\")\n",
        "model2 = load_model(\"/content/drive/MyDrive/dataset/modelLstm.h5\")\n",
        "\n",
        "imagePath = 'test/headshot/headshot_g19c21_frame34.jpg'\n",
        "img_width, img_height = 256, 256\n",
        "img = image.load_img(imagePath, target_size = (img_width, img_height))\n",
        "img = image.img_to_array(img)\n",
        "img = np.expand_dims(img, axis = 0)\n",
        "\n",
        "a = model1.predict(img)\n",
        "\n",
        "print(a)\n",
        "if a[0][2]==1:\n",
        "    print('kick')\n",
        "elif a[0][0]==1:\n",
        "    print('dribling')\n",
        "elif a[0][1]==1:\n",
        "    print('headshot')"
      ],
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[0. 1. 0.]]\n",
            "headshot\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dK56BYwqPn-W",
        "outputId": "6804bb5c-9363-4405-8de8-20e66fa7bb48",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import cv2\n",
        "from tensorflow import keras\n",
        "from keras.preprocessing import image\n",
        "\n",
        "#model1=load_model(\"modelCNN.h5\")\n",
        "model2 = load_model(\"/content/drive/MyDrive/dataset/modelLstm.h5\")\n",
        "\n",
        "imagePath = 'test/dribling/dribling_g22c1_frame18.jpg'\n",
        "img_width, img_height = 256, 256\n",
        "img = image.load_img(imagePath, target_size = (img_width, img_height))\n",
        "img = image.img_to_array(img)\n",
        "img = np.expand_dims(img, axis = 0)\n",
        "\n",
        "a = model1.predict(img)\n",
        "\n",
        "print(a)\n",
        "if a[0][2]==1:\n",
        "    print('kick')\n",
        "elif a[0][0]==1:\n",
        "    print('dribling')\n",
        "elif a[0][1]==1:\n",
        "    print('headshot')"
      ],
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[1. 0. 0.]]\n",
            "dribling\n"
          ]
        }
      ]
    }
  ]
}